"""
Service de base de donn√©es hybride pour Phoenix Rise.

Combine MockDBService (pour le stockage local) avec Phoenix Event Helper (pour la data pipeline).
Assure la compatibilit√© et la transition progressive vers l'Event Sourcing.
"""

import uuid
import logging
import time
from typing import Any, Dict, List
from datetime import datetime

from ..models.journal_entry import JournalEntry
from .mock_db_service import MockDBService
from .phoenix_rise_event_helper import phoenix_rise_event_helper
from ..core.supabase_client import supabase_client
from iris_core.event_processing.emotional_vector_state import EmotionalVectorState
from phoenix_shared_db.services.supabase_batch_service import get_batch_service

# ‚úÖ CORRECTION ARCHITECTURE: Import adaptateur session d√©coupl√©
try:
    from phoenix_shared_ui.adapters import session_manager
except ImportError:
    # Fallback pour d√©veloppement local
    class DummySessionManager:
        def __init__(self): self._data = {}
        def get(self, key, default=None): return self._data.get(key, default)
        def set(self, key, value): self._data[key] = value
        def contains(self, key): return key in self._data
    session_manager = DummySessionManager()

logger = logging.getLogger(__name__)


class HybridDBService:
    """
    üöÄ Service de base de donn√©es hybride optimis√© avec batching intelligent.
    Utilise MockDBService pour le stockage local ET publie les √©v√©nements vers la data pipeline.
    Supporte la persistance EmotionalVectorState via Event Sourcing avec retry/backoff.
    """

    def __init__(self):
        self.mock_service = MockDBService()
        self.event_helper = phoenix_rise_event_helper
        self._supabase_available = self._check_supabase_connection()
        self._batch_service = get_batch_service()
        
        # ‚úÖ Configuration batching optimis√©
        self._pending_events = []
        self._batch_size = 10
        self._batch_timeout = 2.0  # 2 secondes
        self._last_batch_time = time.time()
        self._retry_config = {
            'max_attempts': 3,
            'base_delay': 1.0,
            'max_delay': 10.0,
            'exponential_base': 2
        }
        
        logger.info(f"‚úÖ HybridDBService initialis√© (Mock + Event Sourcing + Batching Optimis√©) - Supabase: {'‚úÖ' if self._supabase_available else '‚ö†Ô∏è'}")
    
    def __del__(self):
        """üîÑ Destructeur - assure le traitement des √©v√©nements en attente."""
        if hasattr(self, '_pending_events') and self._pending_events:
            logger.info(f"üîÑ Traitement final de {len(self._pending_events)} √©v√©nements en attente...")
            try:
                self.force_flush_pending_events()
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du flush final: {e}")
    
    def _check_supabase_connection(self) -> bool:
        """V√©rifie si Supabase est disponible."""
        try:
            # Test simple de connexion
            result = supabase_client.table('events').select('event_id').limit(1).execute()
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Supabase indisponible: {e}")
            return False

    def get_profile(self, user_id: str) -> Dict[str, Any]:
        """R√©cup√®re un profil utilisateur."""
        return self.mock_service.get_profile(user_id)

    def create_profile(
        self, user_id: str, email: str, full_name: str = None
    ) -> Dict[str, Any]:
        """Cr√©e un profil utilisateur."""
        # 1. Cr√©er via Mock (pour compatibilit√© locale)
        profile = self.mock_service.create_profile(user_id, email, full_name)
        
        # 2. Publier √©v√©nement (pour data pipeline)
        try:
            self.event_helper.publish_profile_created(
                user_id=user_id,
                email=email,
                full_name=full_name
            )
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è √âchec publication ProfileCreated: {e}")
        
        return profile

    def get_objectives(self, user_id: str) -> list:
        """R√©cup√®re la liste des objectifs d'un utilisateur."""
        return self.mock_service.get_objectives(user_id)

    def create_objective(
        self,
        user_id: str,
        title: str,
        description: str = None,
        objective_type: str = "personal",
        target_date: str = None,
    ) -> Dict[str, Any]:
        """Cr√©e un nouvel objectif."""
        # 1. Cr√©er via Mock
        objective = self.mock_service.create_objective(
            user_id, title, description, objective_type, target_date
        )
        
        # 2. Publier √©v√©nement (Event Bridge)
        try:
            self.event_helper.publish_objective_created(
                user_id=user_id,
                objective_id=objective["id"],
                objective_title=title,
                objective_type=objective_type,
                target_date=target_date
            )
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è √âchec publication ObjectiveCreated: {e}")
        
        # 3. Stocker √©v√©nement pour EEV
        self.store_event_to_supabase(
            user_id=user_id,
            event_type="GoalSet",
            payload={
                "objective_id": objective["id"],
                "title": title,
                "objective_type": objective_type,
                "target_date": target_date
            }
        )
        
        # 4. Mettre √† jour l'EEV
        evs = self.get_emotional_vector_state(user_id)
        evs.update_action(datetime.utcnow(), "GoalSet")
        self.save_emotional_vector_state(evs)
        
        return objective

    def update_objective(
        self, user_id: str, objective_id: str, updates: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Met √† jour un objectif."""
        return self.mock_service.update_objective(user_id, objective_id, updates)

    def delete_objective(self, user_id: str, objective_id: str) -> bool:
        """Supprime un objectif."""
        return self.mock_service.delete_objective(user_id, objective_id)

    def get_journal_entries(self, user_id: str, limit: int = 50) -> List[JournalEntry]:
        """R√©cup√®re les entr√©es de journal d'un utilisateur."""
        return self.mock_service.get_journal_entries(user_id, limit)

    def create_journal_entry(
        self, user_id: str, mood: int, confidence: int, notes: str = None
    ) -> JournalEntry:
        """Cr√©e une nouvelle entr√©e de journal."""
        # 1. Cr√©er via Mock
        entry = self.mock_service.create_journal_entry(user_id, mood, confidence, notes)
        
        # 2. Publier √©v√©nement MoodLogged (Event Bridge)
        try:
            self.event_helper.publish_mood_logged(
                user_id=user_id,
                mood=mood,
                confidence=confidence,
                notes=notes,
                journal_entry_id=entry.id
            )
            logger.info(f"‚úÖ √âv√©nement MoodLogged publi√© pour entr√©e {entry.id}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è √âchec publication MoodLogged: {e}")
        
        # 3. Stocker √©v√©nement dans Supabase pour EEV
        self.store_event_to_supabase(
            user_id=user_id,
            event_type="MoodLogged",
            payload={
                "score": mood / 10.0,  # Normaliser 1-10 vers 0.1-1.0
                "confidence": confidence,
                "notes": notes,
                "journal_entry_id": entry.id
            }
        )
        
        # 4. Mettre √† jour l'EEV en temps r√©el
        evs = self.get_emotional_vector_state(user_id)
        evs.update_mood(datetime.utcnow(), mood / 10.0)
        evs.update_confidence(datetime.utcnow(), confidence / 10.0)
        self.save_emotional_vector_state(evs)
        
        return entry

    def get_journal_stats(self, user_id: str) -> Dict[str, Any]:
        """R√©cup√®re les statistiques du journal d'un utilisateur."""
        return self.mock_service.get_journal_stats(user_id)

    def start_coaching_session(
        self, 
        user_id: str, 
        session_type: str = "free",
        user_tier: str = "free"
    ) -> str:
        """D√©marre une session de coaching et publie l'√©v√©nement."""
        session_id = str(uuid.uuid4())
        
        # Publier √©v√©nement CoachingSessionStarted
        try:
            self.event_helper.publish_coaching_session_started(
                user_id=user_id,
                session_id=session_id,
                session_type=session_type,
                user_tier=user_tier
            )
            logger.info(f"‚úÖ Session coaching {session_id} d√©marr√©e pour user {user_id}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è √âchec publication CoachingSessionStarted: {e}")
        
        # Stocker √©v√©nement pour EEV
        self.store_event_to_supabase(
            user_id=user_id,
            event_type="CoachingSessionStarted",
            payload={
                "session_id": session_id,
                "session_type": session_type,
                "user_tier": user_tier
            }
        )
        
        return session_id

    def get_event_status(self) -> Dict[str, Any]:
        """Retourne le statut du syst√®me d'√©v√©nements."""
        return {
            "event_bridge_available": self.event_helper.is_available,
            "supabase_available": self._supabase_available,
            "mock_service_active": True,
            "hybrid_mode": True,
            "timestamp": datetime.utcnow().isoformat()
        }
    
    # ===== EMOTIONAL VECTOR STATE - EVENT SOURCING =====
    
    def get_emotional_vector_state(self, user_id: str) -> EmotionalVectorState:
        """R√©cup√®re l'EmotionalVectorState d'un utilisateur via Event Sourcing."""
        if self._supabase_available:
            return self._rebuild_evs_from_events(user_id)
        else:
            # Fallback vers session state pour d√©veloppement
            return self._get_evs_from_session(user_id)
    
    def _rebuild_evs_from_events(self, user_id: str) -> EmotionalVectorState:
        """Reconstruit l'EEV depuis les √©v√©nements stock√©s dans Supabase."""
        try:
            # R√©cup√©rer tous les √©v√©nements pertinents pour ce user
            result = supabase_client.table('events') \
                .select('*') \
                .eq('stream_id', user_id) \
                .in_('event_type', ['MoodLogged', 'ConfidenceScoreLogged', 'CVGenerated', 'SkillSuggested', 'TrajectoryBuilt', 'GoalSet']) \
                .order('timestamp', desc=False) \
                .execute()
            
            events = result.data
            evs = EmotionalVectorState(user_id=user_id)
            
            # Rejouer tous les √©v√©nements pour reconstruire l'√©tat
            for event in events:
                event_formatted = {
                    'type': event['event_type'],
                    'timestamp': event['timestamp'],
                    'payload': event['payload']
                }
                evs.update_from_event(event_formatted)
            
            logger.info(f"‚úÖ EEV reconstruit pour {user_id} depuis {len(events)} √©v√©nements")
            return evs
            
        except Exception as e:
            logger.error(f"‚ùå Erreur reconstruction EEV pour {user_id}: {e}")
            return EmotionalVectorState(user_id=user_id)  # EEV vierge
    
    def _get_evs_from_session(self, user_id: str) -> EmotionalVectorState:
        """‚úÖ D√âCOUPL√â: R√©cup√®re l'EEV depuis session adapt√©e."""
        if not session_manager.contains("emotional_vector_states"):
            session_manager.set("emotional_vector_states", {})
        
        evs_data = session_manager.get("emotional_vector_states", {})
        if user_id not in evs_data:
            evs_data[user_id] = EmotionalVectorState(user_id=user_id)
            session_manager.set("emotional_vector_states", evs_data)
        
        return evs_data[user_id]
    
    def save_emotional_vector_state(self, evs: EmotionalVectorState) -> bool:
        """‚úÖ D√âCOUPL√â: Sauvegarde l'EEV via session adapt√©e."""
        if not session_manager.contains("emotional_vector_states"):
            session_manager.set("emotional_vector_states", {})
        
        evs_data = session_manager.get("emotional_vector_states", {})
        evs_data[evs.user_id] = evs
        session_manager.set("emotional_vector_states", evs_data)
        
        logger.info(f"‚úÖ EEV sauvegard√© pour {evs.user_id}")
        return True
    
    def store_event_to_supabase(self, user_id: str, event_type: str, payload: Dict[str, Any], app_source: str = "rise") -> bool:
        """üöÄ Stocke un √©v√©nement via batch service optimis√© avec retry/backoff."""
        if not self._supabase_available:
            logger.warning(f"‚ö†Ô∏è Supabase indisponible, √©v√©nement {event_type} non persist√©")
            return False
        
        try:
            event_data = {
                "stream_id": user_id,
                "event_type": event_type,
                "payload": payload,
                "app_source": app_source,
                "metadata": {
                    "source": "phoenix_rise_hybrid_service",
                    "version": "1.1.0",
                    "batch_enabled": True
                }
            }
            
            # ‚úÖ Ajouter √† la file de batch au lieu d'√©crire imm√©diatement
            self._add_to_batch(event_data)
            
            # ‚úÖ Traitement batch si conditions remplies
            if self._should_flush_batch():
                return self._flush_batch()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©paration batch √©v√©nement {event_type}: {e}")
            return False
    
    def _add_to_batch(self, event_data: Dict[str, Any]) -> None:
        """Ajoute un √©v√©nement √† la file de batch."""
        self._pending_events.append(event_data)
        logger.debug(f"üì¶ √âv√©nement ajout√© au batch ({len(self._pending_events)}/{self._batch_size})")
    
    def _should_flush_batch(self) -> bool:
        """D√©termine si le batch doit √™tre trait√© maintenant."""
        # Batch par taille
        if len(self._pending_events) >= self._batch_size:
            return True
        
        # Batch par timeout
        if (time.time() - self._last_batch_time) >= self._batch_timeout and self._pending_events:
            return True
        
        return False
    
    def _flush_batch(self) -> bool:
        """üöÄ Traite le batch d'√©v√©nements avec retry/backoff exponential."""
        if not self._pending_events:
            return True
        
        batch_to_process = self._pending_events.copy()
        self._pending_events.clear()
        self._last_batch_time = time.time()
        
        return self._execute_batch_with_retry(batch_to_process)
    
    def _execute_batch_with_retry(self, events: List[Dict[str, Any]]) -> bool:
        """Ex√©cute le batch avec retry/backoff intelligent."""
        last_error = None
        
        for attempt in range(1, self._retry_config['max_attempts'] + 1):
            try:
                # ‚úÖ Utiliser le batch service pour insertion optimis√©e
                if hasattr(self._batch_service, 'batch_insert'):
                    success = self._batch_service.batch_insert('events', events)
                else:
                    # Fallback vers insertion multiple classique
                    result = supabase_client.table('events').insert(events).execute()
                    success = len(result.data) == len(events)
                
                if success:
                    logger.info(f"‚úÖ Batch de {len(events)} √©v√©nements trait√© avec succ√®s (tentative {attempt})")
                    return True
                else:
                    raise Exception("Batch insertion failed - partial success")
                    
            except Exception as e:
                last_error = e
                logger.warning(f"‚ö†Ô∏è √âchec batch tentative {attempt}/{self._retry_config['max_attempts']}: {e}")
                
                if attempt < self._retry_config['max_attempts']:
                    delay = min(
                        self._retry_config['base_delay'] * (self._retry_config['exponential_base'] ** (attempt - 1)),
                        self._retry_config['max_delay']
                    )
                    logger.info(f"‚è≥ Retry dans {delay}s...")
                    time.sleep(delay)
        
        # ‚úÖ √âchec d√©finitif - remettre en file pour retry ult√©rieur
        logger.error(f"‚ùå √âchec d√©finitif batch {len(events)} √©v√©nements apr√®s {self._retry_config['max_attempts']} tentatives: {last_error}")
        self._pending_events.extend(events)  # Remettre en file
        return False
    
    def force_flush_pending_events(self) -> bool:
        """üîÑ Force le traitement imm√©diat de tous les √©v√©nements en attente."""
        if not self._pending_events:
            logger.info("üì¶ Aucun √©v√©nement en attente √† traiter")
            return True
        
        logger.info(f"üîÑ For√ßage traitement {len(self._pending_events)} √©v√©nements en attente...")
        return self._flush_batch()
    
    def get_batch_stats(self) -> Dict[str, Any]:
        """üìä Retourne les statistiques du syst√®me de batching."""
        return {
            "pending_events": len(self._pending_events),
            "batch_size": self._batch_size,
            "batch_timeout_seconds": self._batch_timeout,
            "last_batch_time": datetime.fromtimestamp(self._last_batch_time).isoformat(),
            "time_since_last_batch": time.time() - self._last_batch_time,
            "retry_config": self._retry_config,
            "supabase_available": self._supabase_available
        }