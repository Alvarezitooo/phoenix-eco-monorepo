"""
ü§ñ IRIS API - Assistant IA Phoenix √âcosyst√®me
API FastAPI pour l'agent conversationnel Iris avec authentification s√©curis√©e

Author: Claude Phoenix DevSecOps Guardian
Version: 2.0.0 - Production Ready with Security
"""

import os
import logging
from datetime import datetime
from typing import List, Optional
import hashlib
import time

from fastapi import FastAPI, HTTPException, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from pydantic import BaseModel, Field
import uvicorn
from supabase import create_client

# Imports modules Phoenix
from security.phoenix_auth_standalone import (
    get_authenticated_user, 
    get_optional_authenticated_user, 
    IrisUser, 
    UserTier,
    auth_service
)
from ai.gemini_alessio_engine import alessio_engine, AlessioResponse
from monitoring.iris_analytics import create_analytics, EventType

# Configuration du logger production
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialisation Supabase pour analytics
supabase = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_KEY")
)
analytics = create_analytics(supabase)

# Supprim√©: Fonction d√©plac√©e dans iris_analytics.py

# Initialisation FastAPI
app = FastAPI(
    title="Phoenix Iris API",
    description="API technique h√©bergeant Alessio - Assistant IA Phoenix",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Middleware de s√©curit√©
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["*"]  # En production, restreindre aux domaines autoris√©s
)

# Configuration CORS s√©curis√©e
_iris_allowed_origins_env = os.getenv(
    "IRIS_ALLOWED_ORIGINS",
    "https://phoenix-eco-monorepo.vercel.app,https://phoenix-letters.streamlit.app,https://phoenix-cv.streamlit.app,https://*.streamlit.app,http://localhost:3000,http://localhost:8501,http://localhost:8502",
)
IRIS_ALLOWED_ORIGINS = [origin.strip() for origin in _iris_allowed_origins_env.split(",") if origin.strip()]

app.add_middleware(
    CORSMiddleware,
    allow_origins=IRIS_ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# Middleware de monitoring
@app.middleware("http")
async def monitoring_middleware(request: Request, call_next):
    start_time = time.time()
    
    # Hash de l'IP pour analytics anonymes
    ip_hash = hashlib.sha256(request.client.host.encode()).hexdigest()[:8] if request.client else None
    
    try:
        response = await call_next(request)
        processing_time = (time.time() - start_time) * 1000
        
        # Log des requ√™tes pour monitoring
        logger.info(f"Request: {request.method} {request.url.path} - {response.status_code} - {processing_time:.0f}ms")
        
        return response
    except Exception as e:
        processing_time = (time.time() - start_time) * 1000
        logger.error(f"Request failed: {request.method} {request.url.path} - {processing_time:.0f}ms - Error: {str(e)}")
        
        # Track l'erreur
        await analytics.track_error(
            error_type="request_processing",
            error_message=str(e)
        )
        
        raise

# --- MODELS PYDANTIC ---

class ChatRequest(BaseModel):
    """Requ√™te de chat vers Iris"""
    message: str = Field(..., min_length=1, max_length=2000, description="Message utilisateur")
    context: Optional[str] = Field(None, description="Contexte de la conversation")
    session_id: Optional[str] = Field(None, description="ID de session")
    app_context: Optional[str] = Field(None, description="Application d'origine (letters, cv, rise)")

class ChatResponse(BaseModel):
    """R√©ponse d'Alessio"""
    response: str = Field(..., description="R√©ponse d'Alessio")
    confidence: float = Field(default=0.85, description="Niveau de confiance")
    suggestions: List[str] = Field(default_factory=list, description="Suggestions de suivi")
    timestamp: datetime = Field(default_factory=datetime.now)
    model_used: str = Field(default="gemini-1.5-flash", description="Mod√®le IA utilis√©")
    processing_time_ms: Optional[int] = Field(None, description="Temps de traitement en ms")

# --- SUPPRIM√â: BASE DE CONNAISSANCES STATIQUE ---
# Remplac√©e par le moteur Gemini dynamique

# Base de donn√©es pour fallback uniquement
FALLBACK_RESPONSES = {
    "reconversion": {
        "keywords": ["reconversion", "changer", "m√©tier", "carri√®re", "orientation"],
        "responses": [
            "Pour r√©ussir votre reconversion, commencez par identifier vos comp√©tences transf√©rables. Ces skills peuvent s'appliquer dans votre nouveau domaine !",
            "Une reconversion r√©ussie n√©cessite 3 piliers : l'introspection (vos motivations), la formation (combler les gaps) et le r√©seau (rencontrer des professionnels).",
            "La cl√© d'une reconversion ? Valoriser votre exp√©rience pass√©e comme un atout unique, pas comme un handicap. Votre parcours atypique est votre force !"
        ],
        "suggestions": [
            "Parlez-moi de vos comp√©tences actuelles",
            "Quel domaine vous int√©resse ?",
            "Avez-vous identifi√© des formations ?",
            "Besoin d'aide pour votre CV reconversion ?"
        ]
    },
    "cv": {
        "keywords": ["cv", "curriculum", "candidature", "profil"],
        "responses": [
            "Pour un CV reconversion, structurez-le autour de vos comp√©tences transf√©rables plut√¥t que chronologiquement. Mettez en avant vos r√©alisations quantifi√©es !",
            "Votre CV reconversion doit raconter une histoire coh√©rente : expliquez le lien entre votre pass√© et votre futur projet professionnel.",
            "Conseil CV : utilisez un titre accrocheur qui annonce votre projet (ex: 'Manager commercial ‚Üí D√©veloppeur web') et personnalisez pour chaque offre."
        ],
        "suggestions": [
            "Analysons ensemble votre CV",
            "Comment structurer votre exp√©rience ?",
            "Besoin d'aide pour les mots-cl√©s ATS ?",
            "G√©n√©rer une lettre de motivation ?"
        ]
    },
    "lettre": {
        "keywords": ["lettre", "motivation", "candidature", "postule"],
        "responses": [
            "Une lettre de motivation reconversion doit √™tre authentique : expliquez votre WHY (pourquoi ce changement) et votre HOW (comment vous pr√©parez la transition).",
            "Structure gagnante : 1) Accroche personnalis√©e 2) Votre parcours comme force 3) Votre projet et pr√©paration 4) Appel √† l'action confiant.",
            "Phoenix Letters peut g√©n√©rer votre lettre optimis√©e ! Nos algorithmes analysent l'offre et personnalisent le contenu selon votre profil reconversion."
        ],
        "suggestions": [
            "G√©n√©rer ma lettre avec Phoenix Letters",
            "Comment expliquer ma reconversion ?",
            "Adapter ma lettre √† une offre",
            "√âviter les erreurs classiques"
        ]
    },
    "entretien": {
        "keywords": ["entretien", "oral", "questions", "rencontre", "rdv"],
        "responses": [
            "Pr√©parez 3 histoires STAR (Situation, T√¢che, Action, R√©sultat) qui montrent vos comp√©tences transf√©rables en action. L'entretien, c'est du storytelling !",
            "Face √† la question 'Pourquoi changer de voie ?', soyez authentique mais positif : parlez projet, pas fuite. Montrez que c'est un choix r√©fl√©chi.",
            "Posez des questions intelligentes sur l'√©quipe, les d√©fis du poste, l'√©volution possible. Montrez votre curiosit√© et votre vision long terme !"
        ],
        "suggestions": [
            "Pr√©parer mes r√©ponses types",
            "Comment expliquer ma motivation ?",
            "Quelles questions poser ?",
            "G√©rer le stress de l'entretien"
        ]
    }
}

FALLBACK_RESPONSES = [
    "Je suis Alessio, votre assistant IA Phoenix ! Je vous accompagne dans votre reconversion professionnelle. Comment puis-je vous aider aujourd'hui ?\n\nAlessio ü§ù",
    "Bonjour ! En tant qu'Alessio, je suis l√† pour vous guider dans votre projet de reconversion. CV, lettre de motivation, strat√©gie carri√®re... parlons-en !\n\nAlessio ü§ù",
    "Alessio √† votre service ! Que souhaitez-vous am√©liorer dans votre parcours professionnel ? Je suis sp√©cialis√© dans l'accompagnement aux reconversions.\n\nAlessio ü§ù",
    "Hello ! Pr√™t(e) √† transformer votre carri√®re ? Dites-moi vos d√©fis et objectifs, je suis l√† pour vous √©pauler ! üòä\n\nAlessio ü§ù"
]

# --- LOGIQUE CONVERSATIONNELLE FALLBACK ---

def get_fallback_response(message: str) -> ChatResponse:
    """
    G√©n√®re une r√©ponse de fallback si Gemini est indisponible
    """
    import secrets
    
    response_text = secrets.choice(FALLBACK_RESPONSES)
    
    return ChatResponse(
        response=response_text,
        confidence=0.5,
        suggestions=[
            "Parlez-moi de votre reconversion",
            "Besoin d'aide pour votre CV ?", 
            "Comment optimiser ma candidature ?",
            "Pr√©parer un entretien"
        ],
        model_used="fallback",
        processing_time_ms=0
    )

# --- ENDPOINTS API ---

@app.get("/")
async def root():
    """Endpoint racine - Statut de l'API"""
    return {
        "service": "Phoenix Iris API",
        "status": "‚úÖ Op√©rationnel",
        "version": "2.0.0",
        "description": "Assistant IA conversationnel pour l'√©cosyst√®me Phoenix",
        "features": [
            "Authentification JWT s√©curis√©e",
            "IA Gemini int√©gr√©e", 
            "Rate limiting par tier",
            "Analytics anonymis√©es"
        ],
        "endpoints": {
            "chat": "/api/v1/chat",
            "health": "/health",
            "metrics": "/api/v1/metrics",
            "docs": "/docs"
        }
    }

@app.get("/health")
async def health_check():
    """Health check pour Railway et monitoring"""
    
    # V√©rifications de sant√©
    health_checks = {
        "supabase": "ok",
        "gemini": "ok",
        "auth": "ok"
    }
    
    try:
        # Test rapide Supabase
        supabase.table('iris_events').select('id').limit(1).execute()
    except:
        health_checks["supabase"] = "error"
    
    # Statut global
    overall_status = "healthy" if all(status == "ok" for status in health_checks.values()) else "degraded"
    
    return {
        "status": overall_status,
        "timestamp": datetime.now(),
        "service": "iris-api",
        "version": "2.0.0",
        "environment": os.getenv("ENVIRONMENT", "production"),
        "checks": health_checks
    }

@app.post("/api/v1/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest, user: IrisUser = Depends(get_authenticated_user)):
    """
    Endpoint principal de chat avec Iris - S√âCURIS√â
    N√©cessite une authentification JWT valide
    """
    start_time = time.time()
    
    try:
        # Analytics: Track request
        await analytics.track_chat_request(
            user_id=user.id,
            user_tier=user.tier.value,
            message_length=len(request.message),
            app_context=request.app_context,
            session_id=request.session_id
        )
        
        # Validation message
        if len(request.message.strip()) < 1:
            raise HTTPException(status_code=400, detail="Message ne peut pas √™tre vide")
        
        if len(request.message) > 2000:
            raise HTTPException(status_code=400, detail="Message trop long (max 2000 caract√®res)")
        
        # G√©n√©ration de la r√©ponse Alessio avec Gemini
        try:
            alessio_response = await alessio_engine.generate_response(
                user_message=request.message,
                user_id=user.id,
                context={
                    'user_tier': user.tier.value,
                    'app_context': request.app_context,
                    'session_id': request.session_id
                }
            )
            
            # Incr√©menter l'usage utilisateur
            await auth_service.increment_usage(user.id)
            
            # Construire la r√©ponse FastAPI
            response = ChatResponse(
                response=alessio_response.content,
                confidence=alessio_response.confidence,
                suggestions=alessio_response.suggestions,
                timestamp=datetime.now(),
                model_used=alessio_response.model_used,
                processing_time_ms=alessio_response.processing_time_ms
            )
            
        except Exception as gemini_error:
            logger.error(f"Erreur Gemini: {gemini_error}")
            
            # Fallback sur r√©ponse statique
            response = get_fallback_response(request.message)
            
            # Track l'erreur
            await analytics.track_error(
                error_type="gemini_failure",
                error_message=str(gemini_error),
                user_id=user.id,
                user_tier=user.tier.value
            )
        
        # Analytics: Track response
        processing_time_ms = int((time.time() - start_time) * 1000)
        await analytics.track_chat_response(
            user_id=user.id,
            user_tier=user.tier.value,
            response_length=len(response.response),
            processing_time_ms=processing_time_ms,
            model_used=response.model_used,
            confidence=response.confidence,
            session_id=request.session_id
        )
        
        logger.info(f"Alessio response generated - User: {user.email} - Time: {processing_time_ms}ms")
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors du traitement chat: {str(e)}")
        
        # Track l'erreur
        await analytics.track_error(
            error_type="chat_processing",
            error_message=str(e),
            user_id=user.id if 'user' in locals() else None
        )
        
        raise HTTPException(
            status_code=500,
            detail="Erreur interne du serveur Alessio"
        )

@app.get("/api/v1/topics")
async def get_topics():
    """Liste des sujets que Iris peut traiter"""
    topics = [
        {
            "topic": "reconversion",
            "description": "Conseils pour r√©ussir sa reconversion professionnelle",
            "capabilities": ["Bilan comp√©tences", "Transition secteur", "Formation"]
        },
        {
            "topic": "cv", 
            "description": "Optimisation CV et profil professionnel",
            "capabilities": ["Structure CV", "ATS optimization", "Comp√©tences transf√©rables"]
        },
        {
            "topic": "lettre_motivation",
            "description": "Lettres de motivation percutantes", 
            "capabilities": ["Personnalisation", "Structure", "Authenticit√©"]
        },
        {
            "topic": "entretien",
            "description": "Pr√©paration entretiens d'embauche",
            "capabilities": ["Questions types", "Storytelling STAR", "N√©gociation"]
        },
        {
            "topic": "strategie_carriere",
            "description": "Strat√©gie et d√©veloppement de carri√®re",
            "capabilities": ["LinkedIn", "R√©seau professionnel", "March√© cach√©"]
        }
    ]
    
    return {
        "topics": topics,
        "total": len(topics),
        "description": "Domaines d'expertise d'Alessio pour les reconversions",
        "powered_by": "Google Gemini 1.5 Flash"
    }

# --- ENDPOINTS ANALYTICS & M√âTRIQUES ---

@app.get("/api/v1/metrics")
async def get_public_metrics():
    """M√©triques publiques de l'API (anonymis√©es)"""
    try:
        today_metrics = await analytics.get_daily_metrics(datetime.now())
        
        # M√©triques publiques seulement
        public_metrics = {
            "total_requests_today": today_metrics.get('total_requests', 0),
            "avg_response_time_ms": today_metrics.get('avg_response_time_ms', 0),
            "service_uptime": "99.9%",  # √Ä calculer r√©ellement en production
            "model_used": "Google Gemini 1.5 Flash",
            "last_updated": datetime.now().isoformat()
        }
        
        return public_metrics
        
    except Exception as e:
        logger.error(f"Erreur r√©cup√©ration m√©triques: {e}")
        return {"error": "M√©triques temporairement indisponibles"}

@app.get("/api/v1/user/analytics")
async def get_user_analytics(user: IrisUser = Depends(get_authenticated_user)):
    """Analytics personnelles de l'utilisateur"""
    try:
        user_stats = await analytics.get_user_analytics(user.id, days=30)
        
        # Ajouter infos tier
        tier_limits = auth_service.rate_limits[user.tier]
        
        return {
            "user_tier": user.tier.value,
            "daily_limit": tier_limits["daily_messages"],
            "daily_usage": user.daily_usage,
            "remaining_today": max(0, tier_limits["daily_messages"] - user.daily_usage) if tier_limits["daily_messages"] != -1 else "unlimited",
            "last_30_days": user_stats
        }
        
    except Exception as e:
        logger.error(f"Erreur analytics utilisateur: {e}")
        raise HTTPException(status_code=500, detail="Erreur r√©cup√©ration analytics")

# --- LANCEMENT DE L'APPLICATION ---

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8003))
    
    logger.info(f"ü§ñ D√©marrage Iris API v2.0.0 sur le port {port}")
    logger.info("üöÄ Phoenix Iris API - H√©berge Alessio - Secured AI Assistant Ready!")
    logger.info("üõ°Ô∏è Features: JWT Auth + Alessio AI + Analytics + Rate Limiting")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        log_level="info",
        access_log=True
    )