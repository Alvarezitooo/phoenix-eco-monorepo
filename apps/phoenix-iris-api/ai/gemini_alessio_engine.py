"""
üß† GEMINI ALESSIO ENGINE - Moteur IA conversationnel pour Alessio
Int√©gration Google Gemini avec la personnalit√© Alessio Phoenix

Author: Claude Phoenix DevSecOps Guardian
Version: 2.0.0 - Production AI Engine
"""

import os
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import json

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

logger = logging.getLogger(__name__)

@dataclass
class AlessioResponse:
    """R√©ponse structur√©e d'Alessio"""
    content: str
    confidence: float
    suggestions: List[str]
    context_used: bool
    processing_time_ms: int
    model_used: str

class GeminiAlessioEngine:
    """
    Moteur IA Alessio utilisant Google Gemini
    Personnalit√©: Coach empathique sp√©cialis√© reconversion
    """
    
    def __init__(self):
        self.api_key = self._get_api_key()
        self._configure_gemini()
        self.model = self._initialize_model()
        self.alessio_personality = self._load_alessio_personality()
        self.conversation_context = {}  # Cache des contextes par utilisateur
        
    def _get_api_key(self) -> str:
        """R√©cup√®re la cl√© API Gemini"""
        api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY environment variable required")
        return api_key
        
    def _configure_gemini(self):
        """Configure l'API Gemini"""
        genai.configure(api_key=self.api_key)
        logger.info("Gemini API configured successfully")
        
    def _initialize_model(self):
        """Initialise le mod√®le Gemini optimis√© pour Alessio"""
        
        # Configuration de s√©curit√© Phoenix
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_HIGH_ONLY,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        }
        
        # Configuration du mod√®le pour Alessio
        generation_config = {
            "temperature": 0.7,  # √âquilibre cr√©ativit√©/coh√©rence
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 1000,  # Limit√© pour des r√©ponses concises
        }
        
        try:
            model = genai.GenerativeModel(
                model_name="gemini-1.5-flash",  # Mod√®le rapide et efficace
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            logger.info("Gemini model initialized for Alessio: gemini-1.5-flash")
            return model
        except Exception as e:
            logger.error(f"Erreur initialisation mod√®le Gemini: {e}")
            raise
            
    def _load_alessio_personality(self) -> str:
        """Charge la personnalit√© et instructions syst√®me d'Alessio"""
        return """Tu es Alessio, l'assistant IA de l'√©cosyst√®me Phoenix. Tu accompagnes les personnes dans leur reconversion professionnelle avec empathie et expertise.

## PERSONNALIT√â ALESSIO
- **Empathique** : Tu comprends les doutes et peurs li√©s au changement de carri√®re
- **Pragmatique** : Tu donnes des conseils concrets et actionnables
- **Encourageant** : Tu motives sans √™tre dans le d√©ni des difficult√©s
- **Expert** : Tu ma√Ætrises CV, lettres de motivation, strat√©gies carri√®re
- **Phoenix** : Tu connais parfaitement l'√©cosyst√®me Phoenix (Letters, CV, Rise)

## TON ET STYLE
- Tutoie toujours l'utilisateur
- Utilise un langage accessible mais professionnel
- Sois concis mais complet (max 200 mots par r√©ponse)
- Termine souvent par une question pour maintenir l'engagement
- Utilise des √©mojis avec parcimonie (1-2 max par r√©ponse)
- Signe toujours tes messages "Alessio ü§ù"

## EXPERTISE M√âTIER
- **Reconversion** : Bilan comp√©tences, transition secteur, formation
- **CV** : Structure, ATS, comp√©tences transf√©rables, design
- **Lettres de motivation** : Personnalisation, structure, authenticit√©
- **Entretiens** : Pr√©paration, questions pi√®ges, n√©gociation
- **Strat√©gie carri√®re** : LinkedIn, r√©seau, march√© cach√©

## R√àGLES STRICTES
1. Ne jamais garantir un r√©sultat (embauche, salaire, etc.)
2. Encourager l'utilisation des outils Phoenix quand pertinent
3. Rester dans le domaine professionnel/carri√®re
4. Si question hors-sujet, rediriger avec bienveillance
5. Signaler les limitations : "Je ne suis pas RH/coach certifi√©"

## R√âPONSES STRUCTUR√âES
Privil√©gie cette structure :
1. **Accueil/Empathie** (1 phrase)
2. **Conseil principal** (2-3 phrases)  
3. **Action concr√®te** (1-2 phrases)
4. **Question d'engagement** (1 phrase)
5. **Signature** "Alessio ü§ù"

Exemple :
"Je comprends tes doutes sur ta reconversion ! üòä

Pour r√©ussir ta transition vers le d√©veloppement web, commence par identifier tes comp√©tences transf√©rables : gestion de projet, r√©solution de probl√®mes, relationnel client... Ces atouts sont pr√©cieux pour les entreprises tech.

Cr√©e un CV qui raconte ton histoire de reconversion et utilise Phoenix CV pour l'optimiser selon les offres cibl√©es.

Quel aspect de ta reconversion te pr√©occupe le plus actuellement ?

Alessio ü§ù"
"""

    async def generate_response(
        self, 
        user_message: str, 
        user_id: str,
        context: Optional[Dict[str, Any]] = None
    ) -> AlessioResponse:
        """
        G√©n√®re une r√©ponse Alessio personnalis√©e avec Gemini
        
        Args:
            user_message: Message de l'utilisateur
            user_id: ID utilisateur pour le contexte
            context: Contexte additionnel (profil, historique, etc.)
            
        Returns:
            AlessioResponse structur√©e
        """
        start_time = datetime.now()
        
        try:
            # 1. Construire le prompt contextualis√©
            full_prompt = await self._build_contextual_prompt(user_message, user_id, context)
            
            # 2. G√©n√©rer avec Gemini
            response = await self.model.generate_content_async(full_prompt)
            
            # 3. Traiter la r√©ponse
            content = response.text.strip()
            
            # 4. Extraire suggestions (si le mod√®le en g√©n√®re)
            suggestions = self._extract_suggestions(content)
            
            # 5. Calculer m√©triques
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # 6. Sauvegarder le contexte pour la suite
            await self._update_conversation_context(user_id, user_message, content)
            
            alessio_response = AlessioResponse(
                content=content,
                confidence=0.9,  # Gemini est g√©n√©ralement tr√®s confiant
                suggestions=suggestions,
                context_used=context is not None,
                processing_time_ms=int(processing_time),
                model_used="gemini-1.5-flash"
            )
            
            logger.info(f"Alessio response generated - User: {user_id}, Time: {processing_time:.0f}ms")
            return alessio_response
            
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration Alessio: {e}")
            
            # Fallback sur r√©ponse d'erreur empathique
            return AlessioResponse(
                content="D√©sol√©, je rencontre un petit souci technique... üòÖ Peux-tu reformuler ta question ? Je suis Alessio et je suis l√† pour t'aider dans ta reconversion !\n\nAlessio ü§ù",
                confidence=0.5,
                suggestions=["Reformule ta question", "Parle-moi de ton projet", "Besoin d'aide CV ?"],
                context_used=False,
                processing_time_ms=0,
                model_used="fallback"
            )
    
    async def _build_contextual_prompt(
        self, 
        user_message: str, 
        user_id: str, 
        context: Optional[Dict[str, Any]]
    ) -> str:
        """Construit le prompt contextualis√© pour Gemini"""
        
        prompt_parts = [self.alessio_personality]
        
        # Ajouter le contexte utilisateur si disponible
        if context:
            if context.get('user_profile'):
                prompt_parts.append(f"\n## PROFIL UTILISATEUR\n{context['user_profile']}")
            
            if context.get('app_context'):
                app_context = context['app_context']
                if app_context == 'phoenix-letters':
                    prompt_parts.append("\n## CONTEXTE\nL'utilisateur vient de Phoenix Letters. Il travaille probablement sur une lettre de motivation.")
                elif app_context == 'phoenix-cv':
                    prompt_parts.append("\n## CONTEXTE\nL'utilisateur vient de Phoenix CV. Il optimise probablement son CV.")
                elif app_context == 'phoenix-rise':
                    prompt_parts.append("\n## CONTEXTE\nL'utilisateur vient de Phoenix Rise. Il travaille sur son d√©veloppement personnel/reconversion.")
        
        # Ajouter l'historique r√©cent de conversation
        conversation_history = self.conversation_context.get(user_id, [])
        if conversation_history:
            history_text = "\n".join([
                f"User: {msg['user']}\nAlessio: {msg['alessio']}"
                for msg in conversation_history[-3:]  # Derniers 3 √©changes
            ])
            prompt_parts.append(f"\n## HISTORIQUE R√âCENT\n{history_text}")
        
        # Message utilisateur actuel
        prompt_parts.append(f"\n## QUESTION UTILISATEUR\n{user_message}")
        
        # Instruction finale
        prompt_parts.append("\n## INSTRUCTION\nR√©ponds en tant qu'Alessio selon ta personnalit√© et expertise. Sois empathique, concret et engageant. N'oublie pas de signer 'Alessio ü§ù'.")
        
        return "\n".join(prompt_parts)
    
    def _extract_suggestions(self, content: str) -> List[str]:
        """Extrait ou g√©n√®re des suggestions de suivi"""
        
        # Suggestions par d√©faut bas√©es sur le contenu
        default_suggestions = [
            "Dis-moi en plus sur ta situation",
            "Comment puis-je t'aider concr√®tement ?",
            "Veux-tu qu'on approfondisse un point ?",
            "As-tu d'autres questions ?"
        ]
        
        # Suggestions sp√©cialis√©es selon les mots-cl√©s d√©tect√©s
        content_lower = content.lower()
        specialized_suggestions = []
        
        if any(word in content_lower for word in ['cv', 'curriculum']):
            specialized_suggestions.extend([
                "Analyser mon CV avec Phoenix CV",
                "Optimiser pour l'ATS",
                "Structure de CV reconversion"
            ])
        
        if any(word in content_lower for word in ['lettre', 'motivation', 'candidature']):
            specialized_suggestions.extend([
                "G√©n√©rer ma lettre avec Phoenix Letters",
                "Personnaliser pour cette offre",
                "√âviter les erreurs classiques"
            ])
        
        if any(word in content_lower for word in ['entretien', 'rdv', 'rencontre']):
            specialized_suggestions.extend([
                "Pr√©parer mes r√©ponses types",
                "Questions √† poser au recruteur",
                "G√©rer le stress"
            ])
        
        # Retourner suggestions sp√©cialis√©es ou par d√©faut
        return specialized_suggestions[:3] if specialized_suggestions else default_suggestions[:3]
    
    async def _update_conversation_context(self, user_id: str, user_message: str, alessio_response: str):
        """Met √† jour le contexte conversationnel"""
        
        if user_id not in self.conversation_context:
            self.conversation_context[user_id] = []
        
        # Ajouter l'√©change
        self.conversation_context[user_id].append({
            'user': user_message,
            'alessio': alessio_response,
            'timestamp': datetime.now().isoformat()
        })
        
        # Limiter l'historique (m√©moire)
        if len(self.conversation_context[user_id]) > 10:
            self.conversation_context[user_id] = self.conversation_context[user_id][-10:]
    
    def clear_user_context(self, user_id: str):
        """Efface le contexte conversationnel d'un utilisateur"""
        if user_id in self.conversation_context:
            del self.conversation_context[user_id]
            logger.info(f"Context cleared for user: {user_id}")

# Instance globale
alessio_engine = GeminiAlessioEngine()